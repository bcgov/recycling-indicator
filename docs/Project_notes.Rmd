---
title: "Project_Notes"
author: "G Perkins"
date: "June 5, 2019"
output: 
  html_document: 
    toc : true
    toc_float: 
      collapsed: false
      smooth_scroll: false
      
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# EPR: Project Notes

The dataset provide as part of environment reporting legislation in pdf format and has been transposed to an excel. Detailed information about the program can be found here <https://www2.gov.bc.ca/gov/content/environment/waste-management/recycling/product-stewardship> 

This indicator will be replacing the tire recycling indicator<https://www2.gov.bc.ca/gov/content/environment/research-monitoring-reporting/reporting/environmental-reporting-bc/sustainability-indicators>


## Initial data summary: 

Main indicators: 

- Beverage containers 
- Oil 
- Tires
- Paint-Flam_Pest
- Elect
- Lead-Acid Batteries 
- Packaging and Printed Paper


Along with the BC population measures as of populations for 2018 and program financials and population estimates. 

# Beverage containers. 
Collected from multiple groups: Encorp Pacific (Canada), BC Brewers Recycles Collection Council. Both of these collect data on the units collected, weight collection (tonnes) with population data from 2006 - 2017. There is also some financial data ( revenue/ expenditure /deposits charged / units moved) and other (CO2 Equivalent Reduced (tonnes), weight of material)

Data exploration points to consider:  

- group Encorp and BCBRCC data together by Absolute collection units Collected per regional district 
- BCBRC years may be different. 
- use population rates reported in BCBRCC as first pass. (separate csv)
- timing difference due to 2007/08	2008/09	2009/10 BCBRCC reported as financial years to March 31st 
- some merged cells may be problematic in xlsx/csv processing 
- Comox/Strathcona split into two regions in 2011 onwards only in the Encorp data set - recorded separately for BRCC.
- liquor distribution branch ( 2000 - 2006) only active for short time. 
- Error in 2017 data set in per capita returns for BRCC, better to work off the raw data sets. 

Some notes of caution

- ** FINANCE NOTE: Not all programs report expenditure, and information is not available for all years. These figures represent 'reported' expenditure only (i.e. that included in published annual reports) and should not be taken as total costs of EPR programs.	
- ** OTHER CATERGORY NOTE: Reduced Pollutants refers to pollutants that would have been produced if BLD's recycling system did not exist, and the bottles they would have recycled were instead replaced by containers made from virgin materials.	


Some general conclusions 

- Data can be split in geographic (by regions) or aspatial (BC wide). 
- Regional data: units and tonnes of recycled material & combine with population
- BC wide data: Financial metrics/ units moved / other (tonnes of emissions etc. )


- Key information to work with raw values, finance data and units, 
- Finance data is BC wide, 
- recycling data is regional based. 



## Manual processing
convert to csv, add company name column and a measure category (priority measure, financial, Units Moved,other )
create a separate population csv to be used with the other recycling metrics. 

- create a single pop csv to use in the analysis, error in raw data (population for Caribou missing 10,000)

## Data exploration 
read in the data

```{r loadlibs, echo=FALSE,include = FALSE}
x <- c("dplyr","ggplot2","tidyr","stringr","here", "bcmaps", "readr",
       "sf","envreportutils") 
lapply(x, library, character.only = TRUE) # load the required packages
rm(x)
```

```{r loaddata, echo=TRUE,include = TRUE}
## Load  data files
# ACT: Removed setwd - shouldn't need to do if in a project or using here
data.dir <- soe_path("Operations ORCS/Data - Working/sustainability/EPR")
rdata <- read_csv(file.path(data.dir, "bev.csv"))

# Use here::here to always find a file relative to project root
source(here('00_Functions.R'))

rdata <- read_csv(file.path(data.dir, "bev.csv"))
rdKey <- read_csv(file.path(data.dir, "RD_key.csv"))

#head(rdata)

# extract the population data and export as csv
pop <- rdata %>% 
  filter(Measure == 'Population-') %>%
  select(-c(Company, Catergory, Measure))

pop.long <- gather(pop, "year", "n", 2:19) %>% 
  mutate(year = sub("X", "", year),  # get rid of x on year column
         pop = replaceCommas(n)) # fix the fromatting in numeric

#head(pop.long)
```

## Explore the non spatial data (all regions combined): Financial, units moved and other
1) Financial 

```{r financial, echo=TRUE,include = TRUE}
# Grab the financial data
fdata <- rdata %>% 
  filter(Catergory == 'Financial', 
         !Company == 'EncorpPacific_BRCCC') %>%
  select(-c(Catergory,Region)) %>%
  gather("year", "n",3:20) %>% 
  mutate(
    #fdata$n = sub("$","",fdata$n),  # get rid of x on year column
    n = replaceDollars(n), # fix the fromatting in numeric
    n = replaceCommas(n), # fix the fromatting in numeric
    n.m = n / 1000000,
    year = sub("X", "", year)  # get rid of x on year column
  )

sum.fdata <- fdata %>% 
  group_by(Measure,year) %>%
  summarise(total = sum(n.m, na.rm = TRUE))
```

### How does the amount of revenue influence the number of unclaimed deposits?

```{r unclaimed, echo=TRUE,include = TRUE}
to.keep <- c('Unclaimed Deposits','Expenditure-Consumer Awareness')

sum.fdata <- sum.fdata %>% 
  filter(Measure %in% to.keep )
# Does spending more on consumer awareness decrease unclaimed deposits
ggplot(sum.fdata, aes(year, total, fill = Measure)) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(title = "Unclaimed deposits and consumer-expenditure", 
       x = "Year", y = " Amount ($1,000,000)") + 
  theme(axis.text.x = element_text(angle = 90, hjust = 1))

#ggsave(paste('out/',"01_Beverage_UnitsMoved.png"))

```

There is not a strong correlation between with awareness, may need to adjust this per unit? or check if the awareness expenditure is for multiple programs (ECPOR and BCRCCC)

2) Units Moved
Is there a difference in the units moved (recovered or sold over time?)

```{r Units moved , echo=TRUE,include = TRUE}
udata <- rdata %>% filter(Catergory == 'Units Moved') %>%
  select(-c(Catergory,Region)) %>%
  filter(!Company == 'EncorpPacific_BRCCC') %>%
  filter(!Measure == 'Recovery Rate (%)  Regulation Target 75%') %>%
  gather("year", "n", 3:20) %>% 
  mutate(
    n = replaceCommas(n), # fix the fromatting in numeric
    n.m = n / 1000000,
    year = sub("X", "", year)  # get rid of x on year column
  )

# summarise per year
sum.udata <- udata %>% 
  group_by(Measure, year) %>%
  summarise(total = sum(n.m, na.rm = TRUE))

  # make a pretty graph
ggplot(sum.udata, aes(year, total, fill = Measure)) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(title = "Recycled Units Returned and Sold", 
       x = "Year", y = "Total no. (millions)") + 
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
   # ggsave(paste('out/',"01_Beverage_UnitsMoved.png"))
```
   
   Appears to be a gap in the 2007 and 2008 year that needs to be checked as units show large decrease. 
   Perhaps better to show the recovery rate, rather than recovered and sold (two versus one number)
   
```{r Recovery rate  , echo=TRUE,include = TRUE}    
    #calculate the recovery rate and make a line plot
sum.udata1 <-  udata %>% 
  group_by(Measure, year) %>%
  summarise(total = sum(n.m, na.rm = TRUE)) %>%
  spread(Measure,total) %>% 
  mutate(RecoveryRate = `Units Recovered` / `Units Sold` * 100)


sum.udata1 <- sum.udata1[-1,]

ggplot(sum.udata1, aes(x = year, y = RecoveryRate)) +
  geom_point() +
  ylim(60,100) +
  geom_hline(yintercept = 75, color = "red", lty = 2) +
  labs(title = "Recycled Units Recovery Rate (%)", 
       x = "Year", y = "Recovery Rate %")
      #ggsave(paste('out/',"02_Beverage_UnitsMoved.png"))

```

3. Other category. 
This includes data on the amount of emissions "saved/reduced" and total volumes 

```{r, echo = TRUE}
odata <- rdata %>% filter(Catergory == 'Other') %>%
  select(-c(Company, Catergory,Region)) %>%
  gather("year", "n",2:19) %>% 
  mutate(
    n = replaceCommas(n), # fix the fromatting in numeric
    n.t = n / 1000,
    year = sub("X", "", year),  # get rid of x on year column
    Measure = sub("tonnes", "Tonnes", Measure)  # get rid of x on year column
  )

odata <- odata %>% 
  group_by(Measure, year) %>%
  summarise(total = sum(n.t, na.rm = TRUE))

ggplot(odata, aes(year, total, fill = Measure)) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(title = "Tonnes of material and reduction of pollutants", 
       x = "Year", y = "Tonnes (thousands)") +
  scale_y_continuous(limits = c(0, 250))

```
 
This plot could be reduced or split into two plots emissions saved and emissions and potentially weight of material recycled? 

## Explore the spatial data sets: Units and weight per capita
# 
This includes regional based estimate. Still need to edit the comox Strathcona regions. Also some data entry errors are apparent when calculating the general plots 

```{r explor spatial dataset, echo = TRUE , warn=1}
# extract the raw unit data and add popultaion data 
pdata <- rdata %>% 
  filter(Catergory == 'Priority Measures') %>%
  select(-c(Catergory)) %>%
  filter(!Company == 'EncorpPacific_BRCCC')%>%
  filter(Measure %in% c("Absolute Collection-Units Collected-","Absolute Collection-Weight Collected (Tonnes)-")) %>%
  gather("year", "n",4:21) %>% 
  mutate(
    # format the data tyep 
    year = sub("X", "", year),  # get rid of x on year column
    n = replaceCommas(n) # fix the fromatting in numeric
  )

# group together the multiple companies
sum.pdata <- pdata %>% 
  group_by(Measure, Region, year) %>%
  summarise(total = sum(n, na.rm = TRUE))

# merge in the pop.long form data
ppdata <- left_join(sum.pdata, pop.long, by = c("Region","year")) %>%
  select(-c('n')) %>%
  mutate(unit.per.cap = total / pop)
```
No w data is format split this into different units, tonnes and units per capita and create some summary plots 

```{r split into diffrent unirs and make plots, echo = T, results = T}
# Split data set into weight and units
units.per.cap <- ppdata %>% 
  filter(Measure == 'Absolute Collection-Units Collected-' )
weight.per.cap <-  ppdata %>% 
  filter(Measure == 'Absolute Collection-Weight Collected (Tonnes)-' )

## Units per capita
p1 <- ggplot(units.per.cap, aes(year, unit.per.cap)) + 
  facet_wrap(~Region) +
  geom_bar(stat = "identity",position = "dodge") +
  labs(title = "Regional Units Recycled per capita", 
       x = "Year", y = " units per capita")
# ggsave(paste('out/',"04_Beverage_UnitsPerCap.png"))
p1
```
This plots shows some obvious data errors to check. Also highlights need to adjust Comox and Strathcona datasets as not being correctly calculated. 

```{r weights per capita, echo = T, results = T}
    ## weight per capita
p2 <- ggplot(weight.per.cap,aes(year,unit.per.cap)) + 
  facet_wrap(~Region) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(title = "Regional weight of recycling (tonnes) per capita", 
       x = "Year", y = "weight per cap (tonnes")
#ggsave(paste('out/',"04_Beverage_weightPerCap.png"))
p2

```

Plot 2 also shows similar issue with naming to be fixed 

We can also investigate the difference from the provincial average: 

```{r calculate average and }

# calculate the provincial average
bc.units.per.cap <-  units.per.cap %>% 
  na.omit() %>%
  group_by(year) %>%
  summarise(BCave = mean(unit.per.cap))

regional.units.per.cap <- units.per.cap %>% 
  na.omit() %>%
  group_by(year,Region) %>%
  summarise(ave = mean(unit.per.cap))
# join the regional and prov. ave data and calculate the difference

diff.df <- left_join(regional.units.per.cap,bc.units.per.cap, by = 'year') %>% 
  mutate(delta = ave - BCave, 
         # calculate the deviation from average
         response = ifelse(delta < 0, "below", "above"))


# Diverging Barcharts
p4 <- ggplot(diff.df, aes(x = Region, y = delta, label = delta)) + 
  facet_wrap(~year) +
  geom_bar(stat = 'identity', aes(fill = response), width = 0.5)  +
  scale_fill_manual(name = "Mileage",
                    labels = c("Above Average", "Below Average"),
                    values = c("above" = "#00ba38", "below" = "#f8766d")) +
  labs(title = "Regional difference from the average BC units per capita recycling") +
  coord_flip()
#ggsave(paste('out/',"05_regional_bc_ave_unitsPerCap_per_yr.png"))
p4

# Diverging Barcharts (all years)
p5 <- ggplot(diff.df, aes(x = Region, y = delta, label = delta)) +
  geom_bar(stat = 'identity', aes(fill = response), width = 0.5)  +
  scale_fill_manual(name = "Mileage",
                    labels = c("Above Average", "Below Average"),
                    values = c("above" = "#00ba38", "below" = "#f8766d")) +
  labs(title = "Regional difference from the average BC units per capita recycling") +
  coord_flip()
# ggsave(paste('out/',"06_regional_bc_ave_unitsPerCap_allyrs.png"))
p5
```


Thoughts on Beverage recycling:

- Map regional data sets for presentation (leaflet)
- difference maps better than raw values ? Difference to average works with change per year indicated 
- could present some metrics within graphs (ie non - spatial data sets) 
- Northern Rockies missing population data - need to pull data from stats Canada per year 


# Lubricating Oil, Filters and containers. 

Collection broken in regional and temporal data sets from 2010 to 2017 including: 

- Used oil (litres per person) 
- Used filters (kg per person) 
- Containers (kg per person)
- Antifreeze (kg person)

Data exploration points to consider: 
Temporal and a-spatial data sets include financial, collection sites, units moved, and end fate for products. 
Collection sites does not look like much change in trends over time?
Could be opportunity to combine a number of measure (ie beverage together). Comox and Strathcona are treated separately in this analysis. 

Could also combine the % recover rate over time for different metrics in a single graph 

## Compare regional datasets for priority measures. 
Note these are already calculated per person (assuming the pop data is correct)


```{r loaddata oils, echo=TRUE,include = TRUE}
odata <- read_csv(file.path(data.dir,"LubOilFilt.csv"))

# extract the raw unit data and add with population and maps....
pdata <- odata %>% 
  filter(Catergory == 'Priority Measures', 
                !Region == '') %>%
  gather("year", "n", 4:18) %>% 
  mutate(
    year = sub("X" ,"", year),  # get rid of x on year column
    n = replaceCommas(n), # fix the fromatting in numeric
    n = as.numeric(as.character(n)), # convert to number
  )

pdata <- pdata[complete.cases(pdata),]

## do a basic graph to check it out
ggplot(pdata, aes(year, n, fill = Measure)) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(title = "Absolute collection (kg/litres) per person", 
       x = "Year", y = "Collection (kg) per person")

```

Used oil is a magnitude difference in volume. Repeat graph with out used oil values: 


```{r loaddata oils graph 2, echo=TRUE,include = TRUE}
pdata.1 <- pdata %>% 
  filter(Measure != 'Used Oil - Absolute Collection (litres)-Per Person')
pdata.1 <- pdata.1[complete.cases(pdata.1),]

## do a basic graph to check it out
ggplot(pdata.1,aes(year,n,fill=Measure)) +
  geom_bar(stat="identity",position="dodge") +
  labs(title="Absolute collection (kg) per person", x = "Year", 
       y = "Collection (kg) per person") 
```



# TO DO STILL : 

## Explore the non spatial data (all regions combined): Financial, units moved and other
1) Financial 

```{r financial oil, echo=TRUE,include = TRUE}
# Grab the financial data
#fdata <- rdata %>% filter(Catergory == 'Financial') %>%
#          select(-c(Catergory,Region)) %>%
#          filter(!Company == 'EncorpPacific_BRCCC') %>%
#          gather("year", "n",3:20)
#fdata$n = sub("$","",fdata$n)  # get rid of x on year column
#fdata$n <- replaceDollars(fdata$n) # fix the fromatting in numeric
#fdata$n <- replaceCommas(fdata$n) # fix the fromatting in numeric
#fdata$n.m <-fdata$n/1000000
#fdata$year = sub("X","",fdata$year)  # get rid of x on year column

#sum.fdata <- fdata %>% group_by(Measure,year) %>%
#  summarise(total = sum(n.m,na.rm = TRUE))
```


